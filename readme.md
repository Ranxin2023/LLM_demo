# LLM DEMO
## Concepts
1. How do you measure the performance of an LLM?
### 1.1 ðŸ”¢ Perplexity
- **definition**:
Perplexity is a measurement of how well a language model predicts a sequence. It is the exponential of the average negative log-likelihood of the predicted tokens.
- **formula**:
$$
\text{Perplexity} = e^{\text{Loss}}
$$